{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FILE IO Helpers for galaxy classification/regression project\n",
    "By James Caldon 2021\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "_PARENT_PATH = r\"C:\\Users\\James_Dev_Account\\OneDrive - The University of Western Australia\\Documents\\Honours - Galaxy Classification\\Galaxy-Classification-Research-Project\\generated_data\"\n",
    "_IMAGE_DATA = {\n",
    "    \n",
    "    \"DATA1\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 1000,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"2dft.dat\"\n",
    "            },\n",
    "\n",
    "    \"DATA2\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 1000,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"2dft.dat\"\n",
    "            },\n",
    "\n",
    "    \"DATA3\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 1000,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"2dft.dat\"\n",
    "            },\n",
    "\n",
    "    \"DATA4\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 1000,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"2dft.dat\"\n",
    "            },\n",
    "    \"NAIR_ABRAHAM_2010\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 14034,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"total-list.dat\"\n",
    "            },\n",
    "    \"CG_611\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"N_MODEL\": 1,\n",
    "                \"N_MESH\": 50,\n",
    "                \"FILENAME\": \"cg_611.dat\"\n",
    "            },\n",
    "    \"IC3328\":{\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MODEL\": 1,\n",
    "            \"N_MESH\": 50,\n",
    "            \"FILENAME\": \"ic3328.dat\"\n",
    "            },\n",
    "    \"NGC5845\":{\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MODEL\": 1,\n",
    "            \"N_MESH\": 50,\n",
    "            \"FILENAME\": \"NGC5845.dat\"\n",
    "            }\n",
    "\n",
    "}\n",
    "\n",
    "_ATTR = {\n",
    "    \"NAIR_ABRAHAM_2010\":{\n",
    "                \"DESCRIPTION\": \"TODO\",\n",
    "                \"COUNT\": 14034,\n",
    "                \"FILENAME\": \"T_type.txt\"\n",
    "            }\n",
    "}\n",
    "\n",
    "_DF_METADATA = {\n",
    "    \"DR15_DISC\": {\n",
    "        \"FILEPATH\": r\"dr15\\discs\\ES_SDSS_metadata.txt\"\n",
    "    },\n",
    "    \"DR15_NO_DISC\": {\n",
    "        \"FILEPATH\": r\"dr15\\no_discs\\E_SDSS_metadata.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "_IMAGE_DATA_SETS = {\n",
    "    \n",
    "    \"DISC\":\n",
    "    {\n",
    "        \"MEDIUM_LARGE_DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": '^rgal.*disc_1$',\n",
    "            \"FILENAME\": \"2dft.dat\",\n",
    "            \"CLASS\": 1\n",
    "        },\n",
    "        \"SMALL_LARGE_DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": '^rgal.*disc_1$',\n",
    "            \"FILENAME\": \"2dft.dat\",\n",
    "            \"CLASS\": 1\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"NO_DISC\":\n",
    "    {\n",
    "        \"MEDIUM_LARGE_DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": '^rgal.*disc_2$',\n",
    "            \"FILENAME\": \"2dft.dat\",\n",
    "            \"CLASS\": 0\n",
    "        },\n",
    "        \"SMALL_LARGE_DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": '^rgal.*disc_2$',\n",
    "            \"FILENAME\": \"2dft.dat\",\n",
    "            \"CLASS\": 0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"DR15\":\n",
    "    {\n",
    "        \"DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": 'ES_SDSS_image_data',\n",
    "            \"FILENAME\": \"ES_SDSS_image_data.txt\",\n",
    "            \"CLASS\": 1\n",
    "        },\n",
    "        \"NO_DISCS\":    {\n",
    "            \"DESCRIPTION\": \"TODO\",\n",
    "            \"N_MESH\": 50,\n",
    "            \"FOLDERNAME\": 'E_SDSS_image_data',\n",
    "            \"FILENAME\": \"E_SDSS_image_data.txt\",\n",
    "            \"CLASS\": 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "def load_data_set(data=\"DISC\", data_param=\"SMALL_LARGE_DISCS\", count=None, skip=0):\n",
    "    import re\n",
    "    def load_file(fp):\n",
    "        nrows = None\n",
    "        if count is not None:\n",
    "            nrows = count*n_mesh3\n",
    "        np_arr = pd.read_csv(fp, \n",
    "                             header=None, \n",
    "                             sep='\\s+', \n",
    "                             skiprows=skip*n_mesh3, \n",
    "                             nrows=nrows).to_numpy()\n",
    "        return np_arr.reshape(-1, n_mesh, n_mesh, 1)\n",
    "    x = None\n",
    "    Y = None\n",
    "    n_mesh = _IMAGE_DATA_SETS[data][data_param][\"N_MESH\"]\n",
    "    n_mesh3 = pow(n_mesh, 2)\n",
    "    with os.scandir(os.path.join(_PARENT_PATH, data, data_param)) as dirs:\n",
    "        for entry in dirs:\n",
    "            regex = re.compile(_IMAGE_DATA_SETS[data][data_param][\"FOLDERNAME\"])\n",
    "            if entry.is_dir() and re.match(regex, entry.name):\n",
    "                loaded_file = load_file(os.path.join(entry.path, _IMAGE_DATA_SETS[data][data_param][\"FILENAME\"]))\n",
    "                if x is None:\n",
    "                    x = loaded_file\n",
    "                else:\n",
    "                    x = np.append(x, loaded_file, axis=0)\n",
    "                loaded_file_classes = np.full(loaded_file.shape[0], _IMAGE_DATA_SETS[data][data_param][\"CLASS\"], dtype=np.int)\n",
    "                if Y is None:\n",
    "                    Y = loaded_file_classes\n",
    "                else:\n",
    "                    Y = np.append(Y, loaded_file_classes, axis=0)\n",
    "    return x, Y\n",
    "\n",
    "def load_total_combined_data(data_param=\"SMALL_LARGE_DISCS\", count=None, skip=0):\n",
    "    x_DISC, Y_DISC = load_data_set(data=\"DISC\", data_param=data_param, count=count, skip=skip)\n",
    "    x_NO_DISC, Y_NO_DISC = load_data_set(data=\"NO_DISC\", data_param=data_param, count=count, skip=skip)\n",
    "    x = np.append(x_DISC, x_NO_DISC, axis=0)\n",
    "    Y = np.append(Y_DISC, Y_NO_DISC, axis=0)\n",
    "    return x, Y\n",
    "\n",
    "def load_total_combined_data_DR15(count=None, skip=0):\n",
    "    x_DISC, Y_DISC = load_data_set(data=\"DR15\", data_param=\"DISCS\", count=count, skip=skip)\n",
    "    x_NO_DISC, Y_NO_DISC = load_data_set(data=\"DR15\", data_param=\"NO_DISCS\", count=count, skip=skip)\n",
    "    x = np.append(x_DISC, x_NO_DISC, axis=0)\n",
    "    Y = np.append(Y_DISC, Y_NO_DISC, axis=0)\n",
    "    return x, Y\n",
    "\n",
    "def load_data(data=\"DATA1\", count=None, skip=0):\n",
    "    if (count is None):\n",
    "        n_model = _IMAGE_DATA[data][\"N_MODEL\"]\n",
    "    else:\n",
    "        n_model = count\n",
    "        \n",
    "    \n",
    "    n_mesh = _IMAGE_DATA[data][\"N_MESH\"]\n",
    "    n_mesh3 = pow(n_mesh, 2)\n",
    "    #np_arr = np.genfromtxt(os.path.join(os.path.join(_PARENT_PATH, data), _DATA[data][\"FILENAME\"]), autostrip=True, skip_header=skip*n_mesh3, max_rows=n_model*n_mesh3)\n",
    "    np_arr = pd.read_csv(os.path.join(os.path.join(_PARENT_PATH, data), _IMAGE_DATA[data][\"FILENAME\"]), header=None, sep='\\s+', skiprows=skip*n_mesh3, nrows=n_model*n_mesh3).to_numpy()\n",
    "    return np_arr.reshape(n_model, n_mesh, n_mesh, 1)\n",
    "\n",
    "def load_attribute(data, count=None, skip=0):\n",
    "    if (count is None):\n",
    "        count = _ATTR[data][\"COUNT\"]\n",
    "    np_arr = pd.read_csv(os.path.join(os.path.join(_PARENT_PATH, data), _ATTR[data][\"FILENAME\"]), header=None, sep='\\s+', skiprows=skip, nrows=count).to_numpy()\n",
    "    return np_arr\n",
    "\n",
    "def load_dataframe(data):\n",
    "    df = pd.read_csv(os.path.join(_PARENT_PATH, _DF_METADATA[data][\"FILEPATH\"]), sep=',')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hon-k=2.1.4",
   "language": "python",
   "name": "honours-keras-2.1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
