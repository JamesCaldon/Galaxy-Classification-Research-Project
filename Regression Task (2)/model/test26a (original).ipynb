{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmodel 1000\n",
      "50 50 2499\n",
      "Galaxy type [[4.15999413 3.1924963 ]\n",
      " [4.15999413 3.1924963 ]\n",
      " [4.15999413 3.1924963 ]\n",
      " [4.15999413 3.1924963 ]\n",
      " [4.15999413 3.1924963 ]]\n",
      "Epoch 1/3000\n",
      "1000/1000 [==============================] - 11s 8ms/step - loss: 30.0841 - accuracy: 0.4899 - val_loss: 20.7619 - val_accuracy: 0.5310\n",
      "Epoch 2/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 19.4404 - accuracy: 0.5472 - val_loss: 11.0989 - val_accuracy: 0.5300\n",
      "Epoch 3/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 11.2384 - accuracy: 0.4676 - val_loss: 8.3564 - val_accuracy: 0.5300\n",
      "Epoch 4/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 9.3619 - accuracy: 0.5325 - val_loss: 8.0226 - val_accuracy: 0.5300\n",
      "Epoch 5/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7597 - accuracy: 0.4925 - val_loss: 8.0036 - val_accuracy: 0.5300\n",
      "Epoch 6/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3632 - accuracy: 0.5424 - val_loss: 8.0170 - val_accuracy: 0.5300\n",
      "Epoch 7/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.1466 - accuracy: 0.5280 - val_loss: 7.9948 - val_accuracy: 0.5300\n",
      "Epoch 8/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9131 - accuracy: 0.4992 - val_loss: 7.9744 - val_accuracy: 0.5300\n",
      "Epoch 9/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.2208 - accuracy: 0.5106 - val_loss: 7.9843 - val_accuracy: 0.5300\n",
      "Epoch 10/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9338 - accuracy: 0.4819 - val_loss: 7.9787 - val_accuracy: 0.5300\n",
      "Epoch 11/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8862 - accuracy: 0.5110 - val_loss: 8.0000 - val_accuracy: 0.5300\n",
      "Epoch 12/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.1090 - accuracy: 0.4991 - val_loss: 7.9729 - val_accuracy: 0.5300\n",
      "Epoch 13/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7364 - accuracy: 0.5348 - val_loss: 7.9695 - val_accuracy: 0.5300\n",
      "Epoch 14/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.2159 - accuracy: 0.5224 - val_loss: 7.9788 - val_accuracy: 0.5300\n",
      "Epoch 15/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6343 - accuracy: 0.5039 - val_loss: 7.9738 - val_accuracy: 0.5300\n",
      "Epoch 16/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.0162 - accuracy: 0.4947 - val_loss: 7.9643 - val_accuracy: 0.5300\n",
      "Epoch 17/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.3148 - accuracy: 0.4649 - val_loss: 7.9696 - val_accuracy: 0.5300\n",
      "Epoch 18/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7196 - accuracy: 0.5212 - val_loss: 7.9772 - val_accuracy: 0.5300\n",
      "Epoch 19/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.1538 - accuracy: 0.5117 - val_loss: 7.9500 - val_accuracy: 0.5300\n",
      "Epoch 20/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.0966 - accuracy: 0.5264 - val_loss: 7.9722 - val_accuracy: 0.5300\n",
      "Epoch 21/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.2482 - accuracy: 0.4997 - val_loss: 7.9538 - val_accuracy: 0.5300\n",
      "Epoch 22/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.0539 - accuracy: 0.5179 - val_loss: 7.9513 - val_accuracy: 0.5300\n",
      "Epoch 23/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.4164 - accuracy: 0.4721 - val_loss: 7.9363 - val_accuracy: 0.5300\n",
      "Epoch 24/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7833 - accuracy: 0.4906 - val_loss: 7.9406 - val_accuracy: 0.5300\n",
      "Epoch 25/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9789 - accuracy: 0.5298 - val_loss: 7.9699 - val_accuracy: 0.5300\n",
      "Epoch 26/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9424 - accuracy: 0.4955 - val_loss: 7.9641 - val_accuracy: 0.5300\n",
      "Epoch 27/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6171 - accuracy: 0.4783 - val_loss: 7.9514 - val_accuracy: 0.5300\n",
      "Epoch 28/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8217 - accuracy: 0.5280 - val_loss: 7.9747 - val_accuracy: 0.5300\n",
      "Epoch 29/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6019 - accuracy: 0.4819 - val_loss: 7.9507 - val_accuracy: 0.5300\n",
      "Epoch 30/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.0660 - accuracy: 0.4768 - val_loss: 7.9709 - val_accuracy: 0.5300\n",
      "Epoch 31/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7756 - accuracy: 0.5347 - val_loss: 7.9930 - val_accuracy: 0.5300\n",
      "Epoch 32/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8386 - accuracy: 0.5080 - val_loss: 7.9279 - val_accuracy: 0.5300\n",
      "Epoch 33/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9703 - accuracy: 0.5105 - val_loss: 7.9275 - val_accuracy: 0.5300\n",
      "Epoch 34/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5953 - accuracy: 0.5132 - val_loss: 7.9562 - val_accuracy: 0.5300\n",
      "Epoch 35/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.1530 - accuracy: 0.5013 - val_loss: 7.9239 - val_accuracy: 0.5300\n",
      "Epoch 36/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6890 - accuracy: 0.5005 - val_loss: 7.9522 - val_accuracy: 0.5300\n",
      "Epoch 37/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5122 - accuracy: 0.5455 - val_loss: 7.9505 - val_accuracy: 0.5470\n",
      "Epoch 38/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6224 - accuracy: 0.5103 - val_loss: 7.9455 - val_accuracy: 0.5300\n",
      "Epoch 39/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8045 - accuracy: 0.4977 - val_loss: 7.9305 - val_accuracy: 0.5300\n",
      "Epoch 40/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7122 - accuracy: 0.5350 - val_loss: 7.9198 - val_accuracy: 0.5300\n",
      "Epoch 41/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9927 - accuracy: 0.4828 - val_loss: 7.9149 - val_accuracy: 0.5300\n",
      "Epoch 42/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6682 - accuracy: 0.5287 - val_loss: 7.9269 - val_accuracy: 0.5300\n",
      "Epoch 43/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4035 - accuracy: 0.5326 - val_loss: 7.9539 - val_accuracy: 0.5300\n",
      "Epoch 44/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5797 - accuracy: 0.4817 - val_loss: 7.9136 - val_accuracy: 0.5380\n",
      "Epoch 45/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.5910 - accuracy: 0.5084 - val_loss: 7.9337 - val_accuracy: 0.5300\n",
      "Epoch 46/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6788 - accuracy: 0.5247 - val_loss: 7.9222 - val_accuracy: 0.5300\n",
      "Epoch 47/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8138 - accuracy: 0.4912 - val_loss: 7.9280 - val_accuracy: 0.6040\n",
      "Epoch 48/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8095 - accuracy: 0.5193 - val_loss: 7.9478 - val_accuracy: 0.5300\n",
      "Epoch 49/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8224 - accuracy: 0.5291 - val_loss: 7.9270 - val_accuracy: 0.5300\n",
      "Epoch 50/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.5618 - accuracy: 0.5273 - val_loss: 7.9245 - val_accuracy: 0.5300\n",
      "Epoch 51/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.9846 - accuracy: 0.4626 - val_loss: 7.9128 - val_accuracy: 0.5300\n",
      "Epoch 52/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7542 - accuracy: 0.5060 - val_loss: 7.9057 - val_accuracy: 0.5300\n",
      "Epoch 53/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6595 - accuracy: 0.5067 - val_loss: 7.9256 - val_accuracy: 0.5300\n",
      "Epoch 54/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9674 - accuracy: 0.5110 - val_loss: 7.9184 - val_accuracy: 0.5300\n",
      "Epoch 55/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6197 - accuracy: 0.5320 - val_loss: 7.9064 - val_accuracy: 0.5640\n",
      "Epoch 56/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6629 - accuracy: 0.5210 - val_loss: 7.8939 - val_accuracy: 0.5400\n",
      "Epoch 57/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6272 - accuracy: 0.4768 - val_loss: 7.8989 - val_accuracy: 0.5300\n",
      "Epoch 58/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8588 - accuracy: 0.4812 - val_loss: 7.8972 - val_accuracy: 0.5600\n",
      "Epoch 59/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7765 - accuracy: 0.5213 - val_loss: 7.8883 - val_accuracy: 0.5300\n",
      "Epoch 60/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5494 - accuracy: 0.5041 - val_loss: 7.8956 - val_accuracy: 0.5300\n",
      "Epoch 61/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 9.1629 - accuracy: 0.5037 - val_loss: 7.8730 - val_accuracy: 0.5300\n",
      "Epoch 62/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4703 - accuracy: 0.4894 - val_loss: 7.8802 - val_accuracy: 0.5300\n",
      "Epoch 63/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.9280 - accuracy: 0.5396 - val_loss: 7.8818 - val_accuracy: 0.6070\n",
      "Epoch 64/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6942 - accuracy: 0.5072 - val_loss: 7.8704 - val_accuracy: 0.5590\n",
      "Epoch 65/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8414 - accuracy: 0.5517 - val_loss: 7.8694 - val_accuracy: 0.5600\n",
      "Epoch 66/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8459 - accuracy: 0.5259 - val_loss: 7.8681 - val_accuracy: 0.5600\n",
      "Epoch 67/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6270 - accuracy: 0.5297 - val_loss: 7.8854 - val_accuracy: 0.5300\n",
      "Epoch 68/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4869 - accuracy: 0.5095 - val_loss: 7.8690 - val_accuracy: 0.5630\n",
      "Epoch 69/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.7392 - accuracy: 0.5062 - val_loss: 7.8830 - val_accuracy: 0.5300\n",
      "Epoch 70/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9538 - accuracy: 0.5126 - val_loss: 7.8708 - val_accuracy: 0.5360\n",
      "Epoch 71/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 9.0951 - accuracy: 0.5212 - val_loss: 7.8742 - val_accuracy: 0.5360\n",
      "Epoch 72/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8422 - accuracy: 0.4883 - val_loss: 7.8528 - val_accuracy: 0.5300\n",
      "Epoch 73/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7268 - accuracy: 0.5408 - val_loss: 7.8691 - val_accuracy: 0.5370\n",
      "Epoch 74/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9026 - accuracy: 0.5254 - val_loss: 7.8540 - val_accuracy: 0.5550\n",
      "Epoch 75/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6784 - accuracy: 0.4765 - val_loss: 7.8638 - val_accuracy: 0.5300\n",
      "Epoch 76/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4911 - accuracy: 0.4997 - val_loss: 7.8627 - val_accuracy: 0.5480\n",
      "Epoch 77/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8153 - accuracy: 0.5399 - val_loss: 7.8725 - val_accuracy: 0.5370\n",
      "Epoch 78/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8740 - accuracy: 0.4936 - val_loss: 7.8523 - val_accuracy: 0.5350\n",
      "Epoch 79/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 9.1020 - accuracy: 0.4974 - val_loss: 7.8614 - val_accuracy: 0.5580\n",
      "Epoch 80/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9295 - accuracy: 0.5031 - val_loss: 7.8633 - val_accuracy: 0.5590\n",
      "Epoch 81/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4335 - accuracy: 0.5161 - val_loss: 7.8578 - val_accuracy: 0.5300\n",
      "Epoch 82/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6636 - accuracy: 0.5332 - val_loss: 7.8440 - val_accuracy: 0.6270\n",
      "Epoch 83/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7058 - accuracy: 0.5088 - val_loss: 7.8342 - val_accuracy: 0.5300\n",
      "Epoch 84/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6240 - accuracy: 0.5355 - val_loss: 7.8509 - val_accuracy: 0.5460\n",
      "Epoch 85/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3102 - accuracy: 0.5488 - val_loss: 7.8452 - val_accuracy: 0.5640\n",
      "Epoch 86/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2840 - accuracy: 0.5539 - val_loss: 7.8655 - val_accuracy: 0.5300\n",
      "Epoch 87/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7338 - accuracy: 0.5120 - val_loss: 7.8388 - val_accuracy: 0.5560\n",
      "Epoch 88/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5764 - accuracy: 0.5009 - val_loss: 7.8479 - val_accuracy: 0.5330\n",
      "Epoch 89/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6108 - accuracy: 0.5443 - val_loss: 7.8496 - val_accuracy: 0.5360\n",
      "Epoch 90/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9308 - accuracy: 0.5427 - val_loss: 7.8234 - val_accuracy: 0.5580\n",
      "Epoch 91/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5184 - accuracy: 0.4995 - val_loss: 7.8273 - val_accuracy: 0.5550\n",
      "Epoch 92/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9017 - accuracy: 0.4962 - val_loss: 7.8596 - val_accuracy: 0.5330\n",
      "Epoch 93/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9999 - accuracy: 0.4941 - val_loss: 7.8193 - val_accuracy: 0.6000\n",
      "Epoch 94/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5423 - accuracy: 0.5391 - val_loss: 7.8230 - val_accuracy: 0.5830\n",
      "Epoch 95/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6803 - accuracy: 0.5235 - val_loss: 7.8263 - val_accuracy: 0.5690\n",
      "Epoch 96/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8234 - accuracy: 0.4972 - val_loss: 7.8063 - val_accuracy: 0.6160\n",
      "Epoch 97/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5795 - accuracy: 0.5150 - val_loss: 7.8067 - val_accuracy: 0.5560\n",
      "Epoch 98/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6534 - accuracy: 0.4865 - val_loss: 7.8239 - val_accuracy: 0.5750\n",
      "Epoch 99/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8862 - accuracy: 0.5135 - val_loss: 7.8136 - val_accuracy: 0.5630\n",
      "Epoch 100/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8067 - accuracy: 0.5113 - val_loss: 7.8132 - val_accuracy: 0.5370\n",
      "Epoch 101/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6207 - accuracy: 0.4829 - val_loss: 7.8036 - val_accuracy: 0.5390\n",
      "Epoch 102/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1352 - accuracy: 0.5532 - val_loss: 7.8142 - val_accuracy: 0.5670\n",
      "Epoch 103/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8773 - accuracy: 0.5700 - val_loss: 7.8044 - val_accuracy: 0.6730\n",
      "Epoch 104/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5546 - accuracy: 0.5287 - val_loss: 7.8105 - val_accuracy: 0.6000\n",
      "Epoch 105/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8229 - accuracy: 0.5208 - val_loss: 7.8044 - val_accuracy: 0.5520\n",
      "Epoch 106/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7331 - accuracy: 0.5089 - val_loss: 7.7909 - val_accuracy: 0.5660\n",
      "Epoch 107/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6374 - accuracy: 0.5496 - val_loss: 7.7971 - val_accuracy: 0.5580\n",
      "Epoch 108/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.5236 - accuracy: 0.5010 - val_loss: 7.7900 - val_accuracy: 0.5470\n",
      "Epoch 109/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6855 - accuracy: 0.5092 - val_loss: 7.7832 - val_accuracy: 0.6440\n",
      "Epoch 110/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5390 - accuracy: 0.5273 - val_loss: 7.7830 - val_accuracy: 0.5740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1840 - accuracy: 0.5276 - val_loss: 7.7892 - val_accuracy: 0.5460\n",
      "Epoch 112/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5280 - accuracy: 0.5137 - val_loss: 7.7654 - val_accuracy: 0.5750\n",
      "Epoch 113/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1784 - accuracy: 0.5184 - val_loss: 7.7649 - val_accuracy: 0.5550\n",
      "Epoch 114/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4896 - accuracy: 0.5313 - val_loss: 7.7755 - val_accuracy: 0.5600\n",
      "Epoch 115/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8291 - accuracy: 0.5112 - val_loss: 7.7835 - val_accuracy: 0.6530\n",
      "Epoch 116/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6582 - accuracy: 0.5296 - val_loss: 7.7842 - val_accuracy: 0.7140\n",
      "Epoch 117/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3427 - accuracy: 0.5553 - val_loss: 7.7616 - val_accuracy: 0.6320\n",
      "Epoch 118/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5737 - accuracy: 0.5293 - val_loss: 7.7722 - val_accuracy: 0.6040\n",
      "Epoch 119/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4030 - accuracy: 0.5170 - val_loss: 7.7641 - val_accuracy: 0.6160\n",
      "Epoch 120/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6085 - accuracy: 0.5104 - val_loss: 7.7936 - val_accuracy: 0.5630\n",
      "Epoch 121/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2532 - accuracy: 0.4820 - val_loss: 7.7600 - val_accuracy: 0.5740\n",
      "Epoch 122/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6149 - accuracy: 0.5265 - val_loss: 7.7476 - val_accuracy: 0.5960\n",
      "Epoch 123/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.3036 - accuracy: 0.5338 - val_loss: 7.7728 - val_accuracy: 0.5740\n",
      "Epoch 124/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6255 - accuracy: 0.5183 - val_loss: 7.7646 - val_accuracy: 0.5560\n",
      "Epoch 125/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8625 - accuracy: 0.5223 - val_loss: 7.7609 - val_accuracy: 0.5920\n",
      "Epoch 126/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.7748 - accuracy: 0.5433 - val_loss: 7.7684 - val_accuracy: 0.5640\n",
      "Epoch 127/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6019 - accuracy: 0.4955 - val_loss: 7.7516 - val_accuracy: 0.5690\n",
      "Epoch 128/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6534 - accuracy: 0.5578 - val_loss: 7.7600 - val_accuracy: 0.6770\n",
      "Epoch 129/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2584 - accuracy: 0.5288 - val_loss: 7.7402 - val_accuracy: 0.5860\n",
      "Epoch 130/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8170 - accuracy: 0.5093 - val_loss: 7.7319 - val_accuracy: 0.5700\n",
      "Epoch 131/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4071 - accuracy: 0.5225 - val_loss: 7.7381 - val_accuracy: 0.6160\n",
      "Epoch 132/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.9178 - accuracy: 0.4939 - val_loss: 7.7252 - val_accuracy: 0.6320\n",
      "Epoch 133/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8935 - accuracy: 0.5537 - val_loss: 7.7311 - val_accuracy: 0.6160\n",
      "Epoch 134/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4794 - accuracy: 0.4738 - val_loss: 7.7270 - val_accuracy: 0.7140\n",
      "Epoch 135/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3635 - accuracy: 0.5430 - val_loss: 7.7332 - val_accuracy: 0.5640\n",
      "Epoch 136/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3854 - accuracy: 0.5366 - val_loss: 7.7457 - val_accuracy: 0.5790\n",
      "Epoch 137/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8165 - accuracy: 0.5080 - val_loss: 7.7241 - val_accuracy: 0.5920\n",
      "Epoch 138/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5958 - accuracy: 0.4857 - val_loss: 7.7157 - val_accuracy: 0.5810\n",
      "Epoch 139/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6370 - accuracy: 0.5461 - val_loss: 7.7219 - val_accuracy: 0.5760\n",
      "Epoch 140/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8488 - accuracy: 0.5246 - val_loss: 7.7232 - val_accuracy: 0.6830\n",
      "Epoch 141/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7137 - accuracy: 0.5283 - val_loss: 7.7203 - val_accuracy: 0.6720\n",
      "Epoch 142/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4325 - accuracy: 0.5493 - val_loss: 7.7246 - val_accuracy: 0.6140\n",
      "Epoch 143/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.5281 - accuracy: 0.5400 - val_loss: 7.7253 - val_accuracy: 0.5700\n",
      "Epoch 144/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5261 - accuracy: 0.5490 - val_loss: 7.6993 - val_accuracy: 0.6290\n",
      "Epoch 145/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4390 - accuracy: 0.5369 - val_loss: 7.6879 - val_accuracy: 0.6170\n",
      "Epoch 146/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6925 - accuracy: 0.5221 - val_loss: 7.7035 - val_accuracy: 0.6400\n",
      "Epoch 147/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6947 - accuracy: 0.5331 - val_loss: 7.7205 - val_accuracy: 0.7900\n",
      "Epoch 148/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6125 - accuracy: 0.5289 - val_loss: 7.6889 - val_accuracy: 0.5990\n",
      "Epoch 149/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4776 - accuracy: 0.4944 - val_loss: 7.6833 - val_accuracy: 0.6750\n",
      "Epoch 150/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1308 - accuracy: 0.5350 - val_loss: 7.7107 - val_accuracy: 0.5600\n",
      "Epoch 151/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.6128 - accuracy: 0.5515 - val_loss: 7.6870 - val_accuracy: 0.5980\n",
      "Epoch 152/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.0952 - accuracy: 0.5464 - val_loss: 7.6857 - val_accuracy: 0.6070\n",
      "Epoch 153/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3659 - accuracy: 0.5567 - val_loss: 7.6645 - val_accuracy: 0.6910\n",
      "Epoch 154/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8912 - accuracy: 0.5217 - val_loss: 7.6669 - val_accuracy: 0.5990\n",
      "Epoch 155/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3922 - accuracy: 0.5072 - val_loss: 7.7003 - val_accuracy: 0.5710\n",
      "Epoch 156/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4496 - accuracy: 0.5115 - val_loss: 7.6853 - val_accuracy: 0.5510\n",
      "Epoch 157/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4775 - accuracy: 0.5307 - val_loss: 7.6650 - val_accuracy: 0.5650\n",
      "Epoch 158/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.3563 - accuracy: 0.5494 - val_loss: 7.6602 - val_accuracy: 0.5790\n",
      "Epoch 159/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.7948 - accuracy: 0.5182 - val_loss: 7.6701 - val_accuracy: 0.5930\n",
      "Epoch 160/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.8438 - accuracy: 0.5427 - val_loss: 7.6566 - val_accuracy: 0.6300\n",
      "Epoch 161/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4975 - accuracy: 0.5482 - val_loss: 7.6622 - val_accuracy: 0.6750\n",
      "Epoch 162/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.7967 - accuracy: 0.5546 - val_loss: 7.6930 - val_accuracy: 0.6330\n",
      "Epoch 163/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.5349 - accuracy: 0.5163 - val_loss: 7.6555 - val_accuracy: 0.6160\n",
      "Epoch 164/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5136 - accuracy: 0.5127 - val_loss: 7.6699 - val_accuracy: 0.6450\n",
      "Epoch 165/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.2794 - accuracy: 0.5239 - val_loss: 7.6473 - val_accuracy: 0.6340\n",
      "Epoch 166/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4537 - accuracy: 0.5226 - val_loss: 7.6715 - val_accuracy: 0.6230\n",
      "Epoch 167/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8258 - accuracy: 0.5117 - val_loss: 7.6844 - val_accuracy: 0.6100\n",
      "Epoch 168/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.4341 - accuracy: 0.5355 - val_loss: 7.6628 - val_accuracy: 0.6400\n",
      "Epoch 169/3000\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 8.8696 - accuracy: 0.5655 - val_loss: 7.6379 - val_accuracy: 0.6720\n",
      "Epoch 170/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3085 - accuracy: 0.5731 - val_loss: 7.6321 - val_accuracy: 0.6160\n",
      "Epoch 171/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1840 - accuracy: 0.5138 - val_loss: 7.6341 - val_accuracy: 0.6400\n",
      "Epoch 172/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2377 - accuracy: 0.5393 - val_loss: 7.6399 - val_accuracy: 0.6310\n",
      "Epoch 173/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7032 - accuracy: 0.5321 - val_loss: 7.6235 - val_accuracy: 0.6770\n",
      "Epoch 174/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4860 - accuracy: 0.5131 - val_loss: 7.6163 - val_accuracy: 0.6100\n",
      "Epoch 175/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5985 - accuracy: 0.5426 - val_loss: 7.6174 - val_accuracy: 0.7230\n",
      "Epoch 176/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6302 - accuracy: 0.5266 - val_loss: 7.6239 - val_accuracy: 0.7150\n",
      "Epoch 177/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4966 - accuracy: 0.5300 - val_loss: 7.6170 - val_accuracy: 0.7700\n",
      "Epoch 178/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.0630 - accuracy: 0.5966 - val_loss: 7.6296 - val_accuracy: 0.6160\n",
      "Epoch 179/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1573 - accuracy: 0.5153 - val_loss: 7.6091 - val_accuracy: 0.7780\n",
      "Epoch 180/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5742 - accuracy: 0.4871 - val_loss: 7.5974 - val_accuracy: 0.6910\n",
      "Epoch 181/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3037 - accuracy: 0.5642 - val_loss: 7.6110 - val_accuracy: 0.7390\n",
      "Epoch 182/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6356 - accuracy: 0.5776 - val_loss: 7.5943 - val_accuracy: 0.6600\n",
      "Epoch 183/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3390 - accuracy: 0.5527 - val_loss: 7.5957 - val_accuracy: 0.6740\n",
      "Epoch 184/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.8971 - accuracy: 0.5232 - val_loss: 7.6137 - val_accuracy: 0.6390\n",
      "Epoch 185/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1521 - accuracy: 0.5573 - val_loss: 7.6050 - val_accuracy: 0.6620\n",
      "Epoch 186/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6199 - accuracy: 0.5625 - val_loss: 7.6082 - val_accuracy: 0.6070\n",
      "Epoch 187/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6094 - accuracy: 0.5291 - val_loss: 7.6070 - val_accuracy: 0.5610\n",
      "Epoch 188/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2633 - accuracy: 0.5579 - val_loss: 7.5868 - val_accuracy: 0.6600\n",
      "Epoch 189/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1753 - accuracy: 0.5715 - val_loss: 7.5762 - val_accuracy: 0.6910\n",
      "Epoch 190/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4160 - accuracy: 0.5387 - val_loss: 7.5859 - val_accuracy: 0.7550\n",
      "Epoch 191/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3443 - accuracy: 0.5518 - val_loss: 7.5962 - val_accuracy: 0.6160\n",
      "Epoch 192/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3240 - accuracy: 0.5108 - val_loss: 7.5655 - val_accuracy: 0.5790\n",
      "Epoch 193/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2915 - accuracy: 0.5763 - val_loss: 7.5626 - val_accuracy: 0.6280\n",
      "Epoch 194/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2475 - accuracy: 0.5606 - val_loss: 7.5757 - val_accuracy: 0.7260\n",
      "Epoch 195/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3747 - accuracy: 0.5561 - val_loss: 7.5795 - val_accuracy: 0.6750\n",
      "Epoch 196/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4268 - accuracy: 0.5001 - val_loss: 7.5700 - val_accuracy: 0.6330\n",
      "Epoch 197/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5048 - accuracy: 0.5570 - val_loss: 7.5759 - val_accuracy: 0.6740\n",
      "Epoch 198/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1229 - accuracy: 0.5626 - val_loss: 7.5624 - val_accuracy: 0.6920\n",
      "Epoch 199/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3976 - accuracy: 0.5622 - val_loss: 7.5362 - val_accuracy: 0.7020\n",
      "Epoch 200/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1292 - accuracy: 0.5548 - val_loss: 7.5629 - val_accuracy: 0.6620\n",
      "Epoch 201/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.7430 - accuracy: 0.5604 - val_loss: 7.5399 - val_accuracy: 0.6730\n",
      "Epoch 202/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7215 - accuracy: 0.5296 - val_loss: 7.5304 - val_accuracy: 0.6640\n",
      "Epoch 203/3000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 8.1490 - accuracy: 0.5351 - val_loss: 7.5538 - val_accuracy: 0.6370\n",
      "Epoch 204/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1765 - accuracy: 0.5285 - val_loss: 7.5370 - val_accuracy: 0.6720\n",
      "Epoch 205/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6738 - accuracy: 0.5465 - val_loss: 7.5444 - val_accuracy: 0.6790\n",
      "Epoch 206/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.9738 - accuracy: 0.5949 - val_loss: 7.5497 - val_accuracy: 0.6270\n",
      "Epoch 207/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3677 - accuracy: 0.5972 - val_loss: 7.5250 - val_accuracy: 0.6160\n",
      "Epoch 208/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.7129 - accuracy: 0.5256 - val_loss: 7.5157 - val_accuracy: 0.6500\n",
      "Epoch 209/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.6185 - accuracy: 0.5226 - val_loss: 7.5166 - val_accuracy: 0.7170\n",
      "Epoch 210/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5619 - accuracy: 0.5253 - val_loss: 7.5097 - val_accuracy: 0.6950\n",
      "Epoch 211/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1465 - accuracy: 0.5243 - val_loss: 7.5232 - val_accuracy: 0.6620\n",
      "Epoch 212/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.9580 - accuracy: 0.5832 - val_loss: 7.5060 - val_accuracy: 0.6280\n",
      "Epoch 213/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3747 - accuracy: 0.5622 - val_loss: 7.5278 - val_accuracy: 0.6160\n",
      "Epoch 214/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.0373 - accuracy: 0.5554 - val_loss: 7.4872 - val_accuracy: 0.7510\n",
      "Epoch 215/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3473 - accuracy: 0.5543 - val_loss: 7.4938 - val_accuracy: 0.7620\n",
      "Epoch 216/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.3736 - accuracy: 0.5615 - val_loss: 7.4900 - val_accuracy: 0.6610\n",
      "Epoch 217/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4839 - accuracy: 0.5624 - val_loss: 7.4839 - val_accuracy: 0.6590\n",
      "Epoch 218/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.4154 - accuracy: 0.5274 - val_loss: 7.4830 - val_accuracy: 0.7130\n",
      "Epoch 219/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2426 - accuracy: 0.5510 - val_loss: 7.4799 - val_accuracy: 0.6730\n",
      "Epoch 220/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2963 - accuracy: 0.5598 - val_loss: 7.4963 - val_accuracy: 0.6860\n",
      "Epoch 221/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1512 - accuracy: 0.5388 - val_loss: 7.5021 - val_accuracy: 0.7260\n",
      "Epoch 222/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1544 - accuracy: 0.5728 - val_loss: 7.4679 - val_accuracy: 0.7260\n",
      "Epoch 223/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.8585 - accuracy: 0.5983 - val_loss: 7.4735 - val_accuracy: 0.6970\n",
      "Epoch 224/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.8854 - accuracy: 0.5931 - val_loss: 7.4729 - val_accuracy: 0.7220\n",
      "Epoch 225/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2511 - accuracy: 0.5351 - val_loss: 7.4698 - val_accuracy: 0.7260\n",
      "Epoch 226/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2037 - accuracy: 0.5475 - val_loss: 7.4537 - val_accuracy: 0.6160\n",
      "Epoch 227/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1884 - accuracy: 0.5489 - val_loss: 7.4446 - val_accuracy: 0.6440\n",
      "Epoch 228/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.7122 - accuracy: 0.5632 - val_loss: 7.4650 - val_accuracy: 0.6710\n",
      "Epoch 229/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.2307 - accuracy: 0.5563 - val_loss: 7.4579 - val_accuracy: 0.6180\n",
      "Epoch 230/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.1888 - accuracy: 0.5309 - val_loss: 7.4519 - val_accuracy: 0.7820\n",
      "Epoch 231/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 7.9404 - accuracy: 0.5899 - val_loss: 7.4334 - val_accuracy: 0.7170\n",
      "Epoch 232/3000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 8.5713 - accuracy: 0.5530 - val_loss: 7.4406 - val_accuracy: 0.6220\n",
      "Epoch 233/3000\n",
      " 374/1000 [==========>...................] - ETA: 3s - loss: 7.6631 - accuracy: 0.5681"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This is for morphological classification of galaxies by CNN,\n",
    "New regresssion for B/D ratio\n",
    "By Kenji Bekki, on 2018/3/30\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "### Added 2018/3/30\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import load_model\n",
    "###\n",
    "import keras.callbacks\n",
    "import numpy as np\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "#import tensorflow as tf\n",
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "### Total model number = (100*1) * nmodel\n",
    "\n",
    "#iset=int(input('Input the total number of sets of models '))\n",
    "#nmodel0=int(input('Input the total number of images per model '))\n",
    "#nmodel=nmodel0*iset\n",
    "#epochs=int(input('Input the number of epochs'))\n",
    "#iset=5\n",
    "#nmodel0=100\n",
    "epochs=3000\n",
    "#nmodel=nmodel0*iset\n",
    "nmodel=1000\n",
    "print('nmodel',nmodel)\n",
    "\n",
    "### Original values\n",
    "#batch_size = 128\n",
    "#num_classes = 10\n",
    "#epochs = 12\n",
    "batch_size = 1\n",
    "num_classes = 2\n",
    "#epochs = 500\n",
    "nb_epoch=epochs\n",
    "n_mesh=50\n",
    "#n_mesh=20\n",
    "#nmodel=4000\n",
    "\n",
    "img_rows, img_cols = n_mesh, n_mesh\n",
    "n_mesh2=n_mesh*n_mesh-1\n",
    "n_mesh3=n_mesh*n_mesh\n",
    "\n",
    "\n",
    "print(img_rows, img_cols, n_mesh2)\n",
    "#stop\n",
    "\n",
    "\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#print(y_test.shape[0], 'y.test samples')\n",
    "#print(str(y_test[0]))\n",
    "#print(str(y_test[1]))\n",
    "#print(str(y_test[2]))\n",
    "\n",
    "#y_train = y_train.astype('int32')\n",
    "#y_test = y_test.astype('int32')\n",
    "#y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "#y_test =  keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# This is for simlation data sets\n",
    "\n",
    "with open('2dft.dat') as f:\n",
    "  lines=f.readlines()\n",
    "with open('2dftn1.dat') as f:\n",
    "  lines1=f.readlines()\n",
    "with open('2dftn2.dat') as f:\n",
    "  lines2=f.readlines()\n",
    "\n",
    "\n",
    "x_train=np.zeros((nmodel,n_mesh3))\n",
    "x_test=np.zeros((nmodel,n_mesh3))\n",
    "#y_train=np.zeros(nmodel,dtype=np.int)\n",
    "#y_test=np.zeros(nmodel,dtype=np.int)\n",
    "y_train=np.zeros((nmodel,2))\n",
    "y_test=np.zeros((nmodel,2))\n",
    "#y_test=np.zeros(nmodel)\n",
    "#print(y_train)\n",
    "\n",
    "# For 2D density map data\n",
    "ibin=0\n",
    "jbin=-1\n",
    "for num,j in enumerate(lines):\n",
    "  jbin=jbin+1\n",
    "  tm=j.strip().split()\n",
    "  x_train[ibin,jbin]=float(tm[0])\n",
    "  x_test[ibin,jbin]=float(tm[0])\n",
    "#  print('ibin,jbin',ibin,jbin)\n",
    "  if jbin == n_mesh2:\n",
    "    ibin+=1\n",
    "    jbin=-1\n",
    "\n",
    "# For morphological map (theta)\n",
    "ibin=0\n",
    "for num,j in enumerate(lines1):\n",
    "  tm=j.strip().split()\n",
    "  y_train[ibin,0]=float(tm[0])\n",
    "  y_test[ibin,0]=float(tm[0])\n",
    "#  y_train[ibin]=int(tm[0])-1\n",
    "#  y_test[ibin]=int(tm[0])-1\n",
    "#  print('ibin, (Morpholigcl type)',ibin,y_train[ibin])\n",
    "  ibin+=1\n",
    "\n",
    "# For morphological map (phi)\n",
    "ibin=0\n",
    "for num,j in enumerate(lines2):\n",
    "  tm=j.strip().split()\n",
    "  y_train[ibin,1]=float(tm[0])\n",
    "  y_test[ibin,1]=float(tm[0])\n",
    "#  y_train[ibin]=int(tm[0])-1\n",
    "#  y_test[ibin]=int(tm[0])-1\n",
    "#  print('ibin, (Morpholigcl type)',ibin,y_train[ibin])\n",
    "  ibin+=1\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "# For laelling\n",
    "#y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "#y_test =  keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('Galaxy type',y_train[:5])\n",
    "\n",
    "#stop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "### For labelling of morphological types\n",
    "\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.Adadelta(),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "### For regression of B/D\n",
    "\n",
    "model.add(Dense(2, activation='linear'))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation=('linear'))\n",
    "#model.add(activation=('linear'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print('save the architecture of a model')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-system",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honours",
   "language": "python",
   "name": "honours"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
