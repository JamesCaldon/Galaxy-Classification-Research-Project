{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68babfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\James_Dev_Account\\anaconda3\\envs\\honours-keras-2.1.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unauthorized-support",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmodel 1000\n",
      "50 50 2499\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This is for morphological classification of galaxies by CNN,\n",
    "New regresssion for B/D ratio\n",
    "By Kenji Bekki, on 2018/3/30\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "### Added 2018/3/30\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import load_model\n",
    "###\n",
    "import keras.callbacks\n",
    "import numpy as np\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "#import tensorflow as tf\n",
    "import os.path\n",
    "\n",
    "\n",
    "### Total model number = (100*1) * nmodel\n",
    "\n",
    "#iset=int(input('Input the total number of sets of models '))\n",
    "#nmodel0=int(input('Input the total number of images per model '))\n",
    "#nmodel=nmodel0*iset\n",
    "#epochs=int(input('Input the number of epochs'))\n",
    "iset=5\n",
    "nmodel0=100\n",
    "epochs=1000\n",
    "nmodel=nmodel0*iset\n",
    "nmodel=1000\n",
    "print('nmodel',nmodel)\n",
    "\n",
    "### Original values\n",
    "#batch_size = 128\n",
    "#num_classes = 10\n",
    "#epochs = 12\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "#epochs = 500\n",
    "nb_epoch=epochs\n",
    "n_mesh=50\n",
    "#n_mesh=20\n",
    "#nmodel=4000\n",
    "\n",
    "img_rows, img_cols = n_mesh, n_mesh\n",
    "n_mesh2=n_mesh*n_mesh-1\n",
    "n_mesh3=n_mesh*n_mesh\n",
    "\n",
    "\n",
    "print(img_rows, img_cols, n_mesh2)\n",
    "#stop\n",
    "\n",
    "\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#print(y_test.shape[0], 'y.test samples')\n",
    "#print(str(y_test[0]))\n",
    "#print(str(y_test[1]))\n",
    "#print(str(y_test[2]))\n",
    "\n",
    "#y_train = y_train.astype('int32')\n",
    "#y_test = y_test.astype('int32')\n",
    "#y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "#y_test =  keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# This is for simlation data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "straight-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50, 50, 1)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "x_dataset_series = np.genfromtxt('2dft.dat', autostrip=True, max_rows=nmodel*n_mesh3)\n",
    "y_dataset1 = np.genfromtxt('2dftn1.dat', autostrip=True, max_rows=nmodel)\n",
    "y_dataset2 = np.genfromtxt('2dftn2.dat', autostrip=True, max_rows=nmodel)\n",
    "\n",
    "x_dataset = x_dataset_series.reshape(nmodel, img_rows, img_cols, 1)\n",
    "y_dataset = np.c_[y_dataset1, y_dataset2]\n",
    "\n",
    "print(x_dataset.shape)\n",
    "print(y_dataset.shape)\n",
    "\n",
    "#x_train = x_dataset\n",
    "#x_test = x_dataset\n",
    "\n",
    "#y_train = y_dataset\n",
    "#y_test = y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "homeless-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "successful-watts",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- val_acc: 0.7400\n",
      "Epoch 857/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 3.1375 - acc: 0.7900 - val_loss: 1.9110 - val_acc: 0.8200\n",
      "Epoch 858/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.3487 - acc: 0.8462 - val_loss: 1.6560 - val_acc: 0.8300\n",
      "Epoch 859/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.0881 - acc: 0.8675 - val_loss: 1.6015 - val_acc: 0.8350\n",
      "Epoch 860/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.2338 - acc: 0.8488 - val_loss: 1.6645 - val_acc: 0.8250\n",
      "Epoch 861/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 1.9487 - acc: 0.8600 - val_loss: 1.3360 - val_acc: 0.8500\n",
      "Epoch 862/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.2154 - acc: 0.8625 - val_loss: 1.3943 - val_acc: 0.8600\n",
      "Epoch 863/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.1079 - acc: 0.8600 - val_loss: 1.8202 - val_acc: 0.8350\n",
      "Epoch 864/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.1656 - acc: 0.8700 - val_loss: 1.3727 - val_acc: 0.8650\n",
      "Epoch 865/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.0596 - acc: 0.8525 - val_loss: 2.0663 - val_acc: 0.8000\n",
      "Epoch 866/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.2764 - acc: 0.8450 - val_loss: 1.9013 - val_acc: 0.8100\n",
      "Epoch 867/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.5593 - acc: 0.8438 - val_loss: 1.4773 - val_acc: 0.8050\n",
      "Epoch 868/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.4414 - acc: 0.8200 - val_loss: 1.2629 - val_acc: 0.8600\n",
      "Epoch 869/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.1845 - acc: 0.8625 - val_loss: 1.2154 - val_acc: 0.9150\n",
      "Epoch 870/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.0021 - acc: 0.8675 - val_loss: 1.6025 - val_acc: 0.8200\n",
      "Epoch 871/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 2.3875 - acc: 0.8450 - val_loss: 1.2517 - val_acc: 0.8750\n",
      "Epoch 872/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 1.9853 - acc: 0.8650 - val_loss: 1.9890 - val_acc: 0.7850\n",
      "Epoch 873/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.3448 - acc: 0.8275 - val_loss: 1.5886 - val_acc: 0.8600\n",
      "Epoch 874/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.4093 - acc: 0.8538 - val_loss: 1.3564 - val_acc: 0.8200\n",
      "Epoch 875/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 2.7473 - acc: 0.8150 - val_loss: 1.9008 - val_acc: 0.8000\n",
      "Epoch 876/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.4885 - acc: 0.8375 - val_loss: 2.0148 - val_acc: 0.7700\n",
      "Epoch 877/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 3.7126 - acc: 0.7800 - val_loss: 3.5129 - val_acc: 0.7750\n",
      "Epoch 878/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 4.2510 - acc: 0.7700 - val_loss: 2.3181 - val_acc: 0.7900\n",
      "Epoch 879/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.3378 - acc: 0.8500 - val_loss: 1.2392 - val_acc: 0.8700\n",
      "Epoch 880/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.1200 - acc: 0.8688 - val_loss: 1.2168 - val_acc: 0.8700\n",
      "Epoch 881/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.0302 - acc: 0.8750 - val_loss: 1.8019 - val_acc: 0.8300\n",
      "Epoch 882/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.0224 - acc: 0.8787 - val_loss: 1.6175 - val_acc: 0.8500\n",
      "Epoch 883/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.2840 - acc: 0.8375 - val_loss: 2.0136 - val_acc: 0.7900\n",
      "Epoch 884/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.3215 - acc: 0.8600 - val_loss: 1.6579 - val_acc: 0.8350\n",
      "Epoch 885/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.1151 - acc: 0.8613 - val_loss: 1.3538 - val_acc: 0.8150\n",
      "Epoch 886/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 2.0367 - acc: 0.8638 - val_loss: 1.8204 - val_acc: 0.8400\n",
      "Epoch 887/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.0869 - acc: 0.8700 - val_loss: 1.2638 - val_acc: 0.8800\n",
      "Epoch 888/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.0878 - acc: 0.8663 - val_loss: 1.6572 - val_acc: 0.8850\n",
      "Epoch 889/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.5736 - acc: 0.8263 - val_loss: 2.0099 - val_acc: 0.8500\n",
      "Epoch 890/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.2976 - acc: 0.8363 - val_loss: 2.0821 - val_acc: 0.7650\n",
      "Epoch 891/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.4561 - acc: 0.8388 - val_loss: 1.2513 - val_acc: 0.8950\n",
      "Epoch 892/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.0253 - acc: 0.8625 - val_loss: 1.1887 - val_acc: 0.8950\n",
      "Epoch 893/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.8146 - acc: 0.8788 - val_loss: 1.0488 - val_acc: 0.9050\n",
      "Epoch 894/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.8214 - acc: 0.8850 - val_loss: 2.2676 - val_acc: 0.8100\n",
      "Epoch 895/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.8047 - acc: 0.8400 - val_loss: 3.6549 - val_acc: 0.7750\n",
      "Epoch 896/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 3.0273 - acc: 0.8125 - val_loss: 1.7507 - val_acc: 0.8100\n",
      "Epoch 897/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.2786 - acc: 0.8287 - val_loss: 1.4448 - val_acc: 0.8550\n",
      "Epoch 898/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 3.1439 - acc: 0.8263 - val_loss: 3.0235 - val_acc: 0.7000\n",
      "Epoch 899/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 6.8123 - acc: 0.7138 - val_loss: 66.8697 - val_acc: 0.5400\n",
      "Epoch 900/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 24.3941 - acc: 0.7012 - val_loss: 3.5203 - val_acc: 0.7750\n",
      "Epoch 901/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 3.8081 - acc: 0.7800 - val_loss: 2.7968 - val_acc: 0.7850\n",
      "Epoch 902/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 3.2877 - acc: 0.7788 - val_loss: 2.7522 - val_acc: 0.7850\n",
      "Epoch 903/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 3.1578 - acc: 0.8162 - val_loss: 3.4630 - val_acc: 0.7750\n",
      "Epoch 904/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 3.1848 - acc: 0.8225 - val_loss: 3.2916 - val_acc: 0.7650\n",
      "Epoch 905/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.1432 - acc: 0.8287 - val_loss: 2.5250 - val_acc: 0.7750\n",
      "Epoch 906/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 2.9891 - acc: 0.8162 - val_loss: 2.4528 - val_acc: 0.7750\n",
      "Epoch 907/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.9111 - acc: 0.8238 - val_loss: 2.4294 - val_acc: 0.7750\n",
      "Epoch 908/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.8946 - acc: 0.7950 - val_loss: 2.2280 - val_acc: 0.7800\n",
      "Epoch 909/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 2.5118 - acc: 0.8225 - val_loss: 2.2292 - val_acc: 0.7750\n",
      "Epoch 910/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 2.6107 - acc: 0.8313 - val_loss: 2.0772 - val_acc: 0.7950\n",
      "Epoch 911/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.7602 - acc: 0.8050 - val_loss: 2.5065 - val_acc: 0.7800\n",
      "Epoch 912/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 3.3418 - acc: 0.7812 - val_loss: 2.4937 - val_acc: 0.7950\n",
      "Epoch 913/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.9003 - acc: 0.8187 - val_loss: 2.1174 - val_acc: 0.7750\n",
      "Epoch 914/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.6180 - acc: 0.8312 - val_loss: 2.0216 - val_acc: 0.7850\n",
      "Epoch 915/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.9207 - acc: 0.8200 - val_loss: 2.8112 - val_acc: 0.7650\n",
      "Epoch 916/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 3.1570 - acc: 0.7837 - val_loss: 2.2496 - val_acc: 0.7950\n",
      "Epoch 917/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.9461 - acc: 0.8025 - val_loss: 2.1027 - val_acc: 0.8000\n",
      "Epoch 918/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.7198 - acc: 0.8150 - val_loss: 2.4105 - val_acc: 0.7750\n",
      "Epoch 919/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.6505 - acc: 0.8187 - val_loss: 1.8187 - val_acc: 0.8150\n",
      "Epoch 920/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.3137 - acc: 0.8563 - val_loss: 2.0488 - val_acc: 0.8300\n",
      "Epoch 921/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.9242 - acc: 0.8263 - val_loss: 2.8479 - val_acc: 0.7450\n",
      "Epoch 922/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 2.7007 - acc: 0.8325 - val_loss: 1.7489 - val_acc: 0.8250\n",
      "Epoch 923/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.3986 - acc: 0.8263 - val_loss: 2.4528 - val_acc: 0.7600\n",
      "Epoch 924/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 3.1636 - acc: 0.8125 - val_loss: 3.6275 - val_acc: 0.8000\n",
      "Epoch 925/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.5082 - acc: 0.8388 - val_loss: 1.6366 - val_acc: 0.8650\n",
      "Epoch 926/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.1319 - acc: 0.8563 - val_loss: 1.6087 - val_acc: 0.8350\n",
      "Epoch 927/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.6421 - acc: 0.8137 - val_loss: 2.6863 - val_acc: 0.7300\n",
      "Epoch 928/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.8017 - acc: 0.8012 - val_loss: 1.6925 - val_acc: 0.8550\n",
      "Epoch 929/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.1307 - acc: 0.8588 - val_loss: 2.1249 - val_acc: 0.8450\n",
      "Epoch 930/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.2577 - acc: 0.8713 - val_loss: 2.0052 - val_acc: 0.8550\n",
      "Epoch 931/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.1892 - acc: 0.8537 - val_loss: 1.4941 - val_acc: 0.8600\n",
      "Epoch 932/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.0552 - acc: 0.8688 - val_loss: 1.4271 - val_acc: 0.8700\n",
      "Epoch 933/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.1321 - acc: 0.8625 - val_loss: 1.6062 - val_acc: 0.8250\n",
      "Epoch 934/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.0192 - acc: 0.8338 - val_loss: 1.5681 - val_acc: 0.8350\n",
      "Epoch 935/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.0459 - acc: 0.8612 - val_loss: 1.7119 - val_acc: 0.8550\n",
      "Epoch 936/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.1227 - acc: 0.8900 - val_loss: 1.4421 - val_acc: 0.8300\n",
      "Epoch 937/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.0949 - acc: 0.8675 - val_loss: 1.1869 - val_acc: 0.9150\n",
      "Epoch 938/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.8743 - acc: 0.8812 - val_loss: 1.3280 - val_acc: 0.8500\n",
      "Epoch 939/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.0848 - acc: 0.8600 - val_loss: 1.5713 - val_acc: 0.8200\n",
      "Epoch 940/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.4358 - acc: 0.8213 - val_loss: 1.6740 - val_acc: 0.7750\n",
      "Epoch 941/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.7218 - acc: 0.8112 - val_loss: 2.0269 - val_acc: 0.8650\n",
      "Epoch 942/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 3.4196 - acc: 0.8050 - val_loss: 1.3194 - val_acc: 0.8750\n",
      "Epoch 943/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.8769 - acc: 0.8863 - val_loss: 1.2716 - val_acc: 0.8650\n",
      "Epoch 944/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.9111 - acc: 0.8713 - val_loss: 1.0768 - val_acc: 0.9200\n",
      "Epoch 945/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.9252 - acc: 0.8700 - val_loss: 1.2068 - val_acc: 0.8600\n",
      "Epoch 946/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.7796 - acc: 0.8688 - val_loss: 1.0668 - val_acc: 0.9000\n",
      "Epoch 947/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 1.5613 - acc: 0.8887 - val_loss: 1.2900 - val_acc: 0.8300\n",
      "Epoch 948/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.1638 - acc: 0.8388 - val_loss: 1.5437 - val_acc: 0.8100\n",
      "Epoch 949/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.1639 - acc: 0.8488 - val_loss: 1.4728 - val_acc: 0.8850\n",
      "Epoch 950/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 1.7437 - acc: 0.8912 - val_loss: 1.1091 - val_acc: 0.9100\n",
      "Epoch 951/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 1.8517 - acc: 0.8775 - val_loss: 1.1626 - val_acc: 0.9050\n",
      "Epoch 952/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.7130 - acc: 0.8963 - val_loss: 1.0415 - val_acc: 0.9000\n",
      "Epoch 953/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 2.1051 - acc: 0.8600 - val_loss: 2.1338 - val_acc: 0.8100\n",
      "Epoch 954/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.6392 - acc: 0.8350 - val_loss: 1.3195 - val_acc: 0.8850\n",
      "Epoch 955/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 1.8151 - acc: 0.8763 - val_loss: 1.0973 - val_acc: 0.8950\n",
      "Epoch 956/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.0728 - acc: 0.8650 - val_loss: 1.2464 - val_acc: 0.9100\n",
      "Epoch 957/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.3195 - acc: 0.8787 - val_loss: 1.2774 - val_acc: 0.8800\n",
      "Epoch 958/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.2262 - acc: 0.8650 - val_loss: 2.1379 - val_acc: 0.7500\n",
      "Epoch 959/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.6004 - acc: 0.8125 - val_loss: 1.1717 - val_acc: 0.9200\n",
      "Epoch 960/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.1039 - acc: 0.8625 - val_loss: 1.0281 - val_acc: 0.9300\n",
      "Epoch 961/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.4377 - acc: 0.8688 - val_loss: 1.4473 - val_acc: 0.8900\n",
      "Epoch 962/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.8975 - acc: 0.8888 - val_loss: 0.9984 - val_acc: 0.8950\n",
      "Epoch 963/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.8763 - acc: 0.8638 - val_loss: 1.5826 - val_acc: 0.7950\n",
      "Epoch 964/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 2.9228 - acc: 0.8212 - val_loss: 1.7498 - val_acc: 0.7950\n",
      "Epoch 965/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 4.6286 - acc: 0.7325 - val_loss: 24.7287 - val_acc: 0.5450\n",
      "Epoch 966/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 15.1725 - acc: 0.6613 - val_loss: 5.2207 - val_acc: 0.7400\n",
      "Epoch 967/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 3.6106 - acc: 0.8063 - val_loss: 2.3694 - val_acc: 0.7900\n",
      "Epoch 968/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.5510 - acc: 0.8312 - val_loss: 2.0888 - val_acc: 0.7900\n",
      "Epoch 969/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 2.5191 - acc: 0.8275 - val_loss: 2.0218 - val_acc: 0.7950\n",
      "Epoch 970/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.2294 - acc: 0.8313 - val_loss: 1.8011 - val_acc: 0.8100\n",
      "Epoch 971/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 2.2501 - acc: 0.8513 - val_loss: 1.6617 - val_acc: 0.8100\n",
      "Epoch 972/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 3.0418 - acc: 0.7925 - val_loss: 1.9550 - val_acc: 0.7950\n",
      "Epoch 973/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.2220 - acc: 0.8550 - val_loss: 1.6553 - val_acc: 0.8150\n",
      "Epoch 974/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.4538 - acc: 0.8363 - val_loss: 1.7421 - val_acc: 0.8050\n",
      "Epoch 975/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 2.2391 - acc: 0.8425 - val_loss: 1.5143 - val_acc: 0.8400\n",
      "Epoch 976/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 2.0399 - acc: 0.8487 - val_loss: 1.4434 - val_acc: 0.8500\n",
      "Epoch 977/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.0026 - acc: 0.8700 - val_loss: 1.4041 - val_acc: 0.8300\n",
      "Epoch 978/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 2.3409 - acc: 0.8375 - val_loss: 1.4591 - val_acc: 0.8400\n",
      "Epoch 979/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 2.0959 - acc: 0.8588 - val_loss: 1.3796 - val_acc: 0.8550\n",
      "Epoch 980/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 2.1496 - acc: 0.8525 - val_loss: 1.3802 - val_acc: 0.8450\n",
      "Epoch 981/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.8945 - acc: 0.8725 - val_loss: 1.1515 - val_acc: 0.8800\n",
      "Epoch 982/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.9001 - acc: 0.8688 - val_loss: 1.2170 - val_acc: 0.8750\n",
      "Epoch 983/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 1.8639 - acc: 0.8837 - val_loss: 1.2955 - val_acc: 0.8650\n",
      "Epoch 984/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.9642 - acc: 0.8475 - val_loss: 1.2871 - val_acc: 0.8750\n",
      "Epoch 985/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 1.9184 - acc: 0.8588 - val_loss: 1.0927 - val_acc: 0.8850\n",
      "Epoch 986/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.9517 - acc: 0.8750 - val_loss: 1.0865 - val_acc: 0.8950\n",
      "Epoch 987/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 1.8933 - acc: 0.8825 - val_loss: 1.1654 - val_acc: 0.8700\n",
      "Epoch 988/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 1.9727 - acc: 0.8850 - val_loss: 1.2655 - val_acc: 0.8700\n",
      "Epoch 989/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.7165 - acc: 0.8725 - val_loss: 1.0479 - val_acc: 0.8950\n",
      "Epoch 990/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 1.8355 - acc: 0.8700 - val_loss: 1.1780 - val_acc: 0.8700\n",
      "Epoch 991/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.7378 - acc: 0.8675 - val_loss: 0.9358 - val_acc: 0.9200\n",
      "Epoch 992/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.8268 - acc: 0.8862 - val_loss: 1.1088 - val_acc: 0.8750\n",
      "Epoch 993/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.9462 - acc: 0.8800 - val_loss: 1.1110 - val_acc: 0.8550\n",
      "Epoch 994/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.8068 - acc: 0.8687 - val_loss: 1.6917 - val_acc: 0.8050\n",
      "Epoch 995/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 2.4811 - acc: 0.8538 - val_loss: 3.3324 - val_acc: 0.7050\n",
      "Epoch 996/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 2.2561 - acc: 0.8687 - val_loss: 1.0342 - val_acc: 0.8950\n",
      "Epoch 997/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 1.9194 - acc: 0.8788 - val_loss: 0.9697 - val_acc: 0.9150\n",
      "Epoch 998/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.7782 - acc: 0.8862 - val_loss: 1.2208 - val_acc: 0.8300\n",
      "Epoch 999/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.7067 - acc: 0.8675 - val_loss: 1.1985 - val_acc: 0.9100\n",
      "Epoch 1000/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 1.9325 - acc: 0.8850 - val_loss: 1.4765 - val_acc: 0.8550\n",
      "Test score: 1.4765243816375733\n",
      "Test accuracy: 0.855\n",
      "save the architecture of a model\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "print('Galaxy type',y_train[:5])\n",
    "\n",
    "#stop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "### For labelling of morphological types\n",
    "\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.Adadelta(),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "### For regression of B/D\n",
    "\n",
    "model.add(Dense(2, activation='linear'))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation=('linear'))\n",
    "#model.add(activation=('linear'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print('save the architecture of a model')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hon-k=2.1.4",
   "language": "python",
   "name": "honours-keras-2.1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
