{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "productive-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mesh = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "israeli-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath = \"..\\\\data\\\\raw\\\\testing\\\\nair_abraham_2010\", count=None, skip=0):\n",
    "    import os\n",
    "    def load_files_in_directory(folderpath):\n",
    "        x = []\n",
    "        with os.scandir(folderpath) as dirs:\n",
    "            for entry in dirs:\n",
    "                if entry.is_file() and entry.name.endswith(\".dat\"):\n",
    "                    loaded_file = pd.read_csv(entry.path, header=None, sep='\\s+', skiprows=skip*mesh*mesh, nrows=count).to_numpy()\n",
    "                    x = np.append(x, loaded_file)  \n",
    "                if entry.is_dir():\n",
    "                    loaded_file = load_files_in_directory(entry.path)\n",
    "                    x = np.append(x, loaded_file)  \n",
    "        return np.array(x)\n",
    "                    \n",
    "    x = []; Y = []\n",
    "    \n",
    "    \n",
    "    with os.scandir(filepath) as dirs:\n",
    "\n",
    "        for entry in dirs:\n",
    "            if entry.is_dir() and entry.name.__contains__(\"unknown\"):\n",
    "                x = np.append(x, load_files_in_directory(entry.path))\n",
    "                \n",
    "            elif entry.is_dir() and entry.name.__contains__(\"no_disc\"):\n",
    "                loaded_no_discs = load_files_in_directory(entry.path)\n",
    "                x = np.append(x, loaded_no_discs)\n",
    "                Y = np.append(Y, np.full(int(loaded_no_discs.shape[0]/(mesh*mesh)), \"E\"))\n",
    "                \n",
    "            elif entry.is_dir() and entry.name.__contains__(\"disc\"):\n",
    "                loaded_discs = load_files_in_directory(entry.path)\n",
    "                x = np.append(x, loaded_discs)\n",
    "                Y = np.append(Y, np.full(int(loaded_discs.shape[0]/(mesh*mesh)), \"ES\"))\n",
    "                \n",
    "    return np.array(x).reshape(-1, mesh, mesh, 1), np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organizational-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\testing\\\\nair_abraham_2010\", name=\"nair_abraham_2010.fits\"):\n",
    "    from astropy.io import fits\n",
    "    from astropy.table import Table\n",
    "    from matplotlib import pyplot as plt\n",
    "    image_data, Y = load_dataset(filepath)\n",
    "    plt.imshow(image_data[0])\n",
    "\n",
    "    class_data = Table.from_pandas(pd.DataFrame(Y, columns=[\"class\"]))\n",
    "    primary_hdu = fits.PrimaryHDU(image_data)\n",
    "    table_hdu = fits.table_to_hdu(class_data)\n",
    "    hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "    hdul.writeto(name, overwrite=True)\n",
    "    \n",
    "    with fits.open(name) as hdul:\n",
    "        img_arr = np.array(hdul[0].data)\n",
    "        img_class = hdul[1].data\n",
    "    print(img_class)\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(img_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alive-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_califa_data_to_fits():\n",
    "    from astropy.io import fits\n",
    "    from astropy.table import Table\n",
    "\n",
    "    ES = pd.read_csv(r\"..\\data\\raw\\testing\\dr15\\disc\\ES_SDSS_metadata.txt\", sep=',', usecols=[1, 2, 3])\n",
    "    ES[\"class\"] = \"BD/ES\"\n",
    "    E = pd.read_csv(r\"..\\data\\raw\\testing\\dr15\\no_disc\\E_SDSS_metadata.txt\", sep=',', usecols=[1, 2, 3])\n",
    "    E[\"class\"] = \"E\"\n",
    "    ES_E = ES.append(E)\n",
    "    fits_BD_E = Table.from_pandas(ES_E)\n",
    "    print(fits_BD_E)\n",
    "    DR15, y = load_dataset(filepath = \"..\\\\data\\\\raw\\\\testing\\\\dr15\")\n",
    "\n",
    "    primary_hdu = fits.PrimaryHDU(DR15)\n",
    "    table_hdu = fits.table_to_hdu(fits_BD_E, character_as_bytes=True)\n",
    "    print(table_hdu)\n",
    "    hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "    hdul.writeto('califa.fits', overwrite=True)\n",
    "\n",
    "    CALIFA_FP = 'califa.fits'\n",
    "    with fits.open(CALIFA_FP) as hdul:\n",
    "        hdul.info()\n",
    "\n",
    "        img_arr = np.array(hdul[0].data)\n",
    "        img_class = hdul[1].data[0]\n",
    "    print(img_class)\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(img_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gross-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_graham_data_to_fits():\n",
    "    from astropy.io import fits\n",
    "    from astropy.table import Table\n",
    "\n",
    "    ES = pd.read_csv(r\"..\\data\\raw\\testing\\graham\\disc\\ES_graham_metadata.txt\", sep=',', usecols=[1, 2, 3, 4, 5])\n",
    "    ES.rename(columns = {\"Type\":\"class\"}, inplace = True)\n",
    "    ES.rename(columns = {\"Galaxy\":\"name\"}, inplace = True)\n",
    "    #ES[\"class\"] = \"ES\"\n",
    "    E = pd.read_csv(r\"..\\data\\raw\\testing\\graham\\no_disc\\E_graham_metadata.txt\", sep=',', usecols=[1, 2, 3, 4, 5])\n",
    "    E.rename(columns = {\"Type\":\"class\"}, inplace = True)\n",
    "    E.rename(columns = {\"Galaxy\":\"name\"}, inplace = True)\n",
    "    #E[\"class\"] = \"E\"\n",
    "    ES_E = ES.append(E)\n",
    "    fits_BD_E = Table.from_pandas(ES_E)\n",
    "    print(fits_BD_E)\n",
    "    graham, y = load_dataset(filepath = \"..\\\\data\\\\raw\\\\testing\\\\graham\")\n",
    "\n",
    "    primary_hdu = fits.PrimaryHDU(graham)\n",
    "    table_hdu = fits.table_to_hdu(fits_BD_E, character_as_bytes=True)\n",
    "    print(table_hdu)\n",
    "    hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "    hdul.writeto('graham.fits', overwrite=True)\n",
    "\n",
    "    graham_fp = 'graham.fits'\n",
    "    with fits.open(graham_fp) as hdul:\n",
    "        hdul.info()\n",
    "\n",
    "        img_arr = np.array(hdul[0].data)\n",
    "        img_class = hdul[1].data[0]\n",
    "    print(img_class)\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(img_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preliminary-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_califa_data_to_fits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "norman-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_graham_data_to_fits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "general-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\testing\\\\nair_abraham_2010\", name=\"nair_abraham_2010.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fewer-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.9-0.95_discs\", name=\"fd=0.9-0.95.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separated-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.5-0.9_discs\", name=\"fd=0.5-0.9.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chinese-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.3-0.5_discs\", name=\"fd=0.3-0.5.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacterial-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.3-0.7_discs\", name=\"fd=0.3-0.7.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fleet-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.3-0.9_discs\", name=\"fd=0.3-0.9.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atomic-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.7-0.9_discs\", name=\"fd=0.7-0.9.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "requested-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.5-0.7_discs\", name=\"fd=0.5-0.7.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alone-reducing",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1080108000 into shape (100,100,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ba7202074f7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_to_fits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"..\\\\data\\\\raw\\\\training\\\\fd=0.3-0.6_discs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fd=0.3-0.6.fits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-94819e7fb614>\u001b[0m in \u001b[0;36mraw_to_fits\u001b[1;34m(filepath, name)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b808d26c86d7>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(filepath, count, skip)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_discs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ES\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1080108000 into shape (100,100,1)"
     ]
    }
   ],
   "source": [
    "#raw_to_fits(filepath = \"..\\\\data\\\\raw\\\\training\\\\fd=0.3-0.6_discs\", name=\"fd=0.3-0.6.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from astropy.io import fits\n",
    "#from astropy.table import Table\n",
    "#graham_fp = 'NGC_3923_I_IIIaJ_dss1.fits'\n",
    "#with fits.open(graham_fp) as hdul:\n",
    "#    hdul.info()\n",
    "#\n",
    "#    img_arr = np.array(hdul[0].data)\n",
    "#from matplotlib import pyplot as plt\n",
    "#plt.imshow(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utility/data_loading.ipynb\n",
    "x_val, Y_val, metadata = load_data(name=\"califa\")\n",
    "class_labels = np.unique(metadata[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ..\\utility\\plotting_helpers.ipynb\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [10, 10]\n",
    "mpl.rcParams['figure.dpi'] = 72\n",
    "plot_classification_results(images=x_val, y_preds=Y_val, y_trues=Y_val,\n",
    "                            y_labels=(class_labels[1], class_labels[0]),\n",
    "                            galaxy_names=metadata[\"name\"], random_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-machine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc4ea8e3b391f2ee90aeb9686476053ed668d7d8817dfe041f95da3f8dff18a2"
  },
  "kernelspec": {
   "display_name": "hon",
   "language": "python",
   "name": "hon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
