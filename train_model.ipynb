{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bba0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "sys.path.insert(0, \"..\\\\utility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6350ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import initialize_tf\r\n",
    "import tensorflow as tf\r\n",
    "from data_loading import *\r\n",
    "from data_preprocessing import *\r\n",
    "from plotting_helpers import *\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib as mpl\r\n",
    "from matplotlib import pyplot\r\n",
    "import numpy as np\r\n",
    "%matplotlib inline\r\n",
    "mpl.rcParams['figure.figsize'] = [10, 10]\r\n",
    "mpl.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52445680",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_name = \"fd=0.3-0.7_hdf5\"\r\n",
    "testing_data = \"califa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d01b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\honours\\lib\\site-packages\\tables\\path.py:155: NaturalNameWarning: object name is a Python keyword: 'class'; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 100, 100)\n",
      "(54000, 100, 100)\n",
      "(54000,)\n"
     ]
    }
   ],
   "source": [
    "x_dataset_orig, y_dataset_orig, metadata_orig = load_hdf5_data(name=training_data_name, count=None)\r\n",
    "num_classes = 2 # get from unique\r\n",
    "print(x_dataset_orig.shape)\r\n",
    "print(y_dataset_orig.shape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aac607",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_results(images=x_dataset_orig, y_preds=y_dataset_orig, y_trues=y_dataset_orig, y_labels=(\"No Disc\", \"Disc\"), random_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = x_dataset_orig.copy()\r\n",
    "y_dataset = y_dataset_orig.copy()\r\n",
    "metadata = metadata_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3672ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_point_sources(x_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_background_galaxies(x_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3dd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gaussian_PSF(x_dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2960f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_gaussian_noise(x_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_results(images=x_dataset, y_preds=y_dataset, y_trues=y_dataset, y_labels=(\"No Disc\", \"Disc\"), random_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166457fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = np.expand_dims(x_dataset, axis=3)\r\n",
    "input_shape = x_dataset[0].shape\r\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b29e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(x_dataset, y_dataset):\r\n",
    "\r\n",
    "    from sklearn import model_selection\r\n",
    "    x_val, Y_val, metadata = load_hdf5_data(name=testing_data)\r\n",
    "    x_val = np.expand_dims(x_val, axis=3)\r\n",
    "    #Y_val = tf.keras.utils.to_categorical(Y_val, num_classes)\r\n",
    "    print(x_val.shape)\r\n",
    "\r\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(x_dataset, y_dataset, train_size=0.8, random_state=1)\r\n",
    "\r\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\r\n",
    "\r\n",
    "    epochs = 20\r\n",
    "    batch_size = 64\r\n",
    "    model = tf.keras.Sequential([\r\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\r\n",
    "                        activation='relu',\r\n",
    "                        input_shape=input_shape),\r\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
    "        tf.keras.layers.Dropout(0.25),\r\n",
    "        tf.keras.layers.Flatten(),\r\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\r\n",
    "        tf.keras.layers.Dropout(0.5),\r\n",
    "        tf.keras.layers.Dense(x_dataset.shape[0], activation='softmax')\r\n",
    "    ])\r\n",
    "\r\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n",
    "                    optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0),\r\n",
    "                    metrics=['accuracy'])\r\n",
    "\r\n",
    "    train_history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\r\n",
    "        verbose=1, validation_data=(x_val, Y_val), callbacks=[callback])\r\n",
    "    pyplot.plot(train_history.history['loss'])\r\n",
    "    pyplot.plot(train_history.history['val_loss'])\r\n",
    "    pyplot.legend(['loss', 'val_loss'])\r\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch in range(epochs):\r\n",
    "#      history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1,\r\n",
    "#            verbose=1, validation_data=(x_test, y_test))\r\n",
    "#      loss = history.history['loss']\r\n",
    "      #score = model.evaluate(x_test, y_test, verbose=0)\r\n",
    "      #print('Test score:', score[0])\r\n",
    "      #print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"saved_models\\simulation_psf_\" + str(psf_sigma), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc4ea8e3b391f2ee90aeb9686476053ed668d7d8817dfe041f95da3f8dff18a2"
  },
  "kernelspec": {
   "display_name": "hon",
   "language": "python",
   "name": "hon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
